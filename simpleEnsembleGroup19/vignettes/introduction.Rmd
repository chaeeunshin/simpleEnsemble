---
title: "introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(simpleEnsembleGroup19)
```

# check_data
This function check if the response variable is binary or continuous. If response variable is categorical (factor or character with two levels), it changes response variable into binary(0 or 1). This function returns two output, one is feature of response variable(binary or continous) and the other is binary(0 or 1) or continuous response variable
```{r}
check_data(bin.x,bin.y)
check_data(bin.x,bin.y)$response_type
check_data(bin.x,bin.y)$y

check_data(cont.x,cont.y)
check_data(cont.x,cont.y)$response_type
check_data(cont.x,cont.y)$y
```

# train_test(X,y,p) 
This function generate train and test data for machine learning. In addition to matrix X and vector y, user is required to determine p, which is proportion of train data. If p is not given, it splits train and test data by proportion of 0.8. It returns train_X,train_y,test_X, and test_y.
```{r}
traintest <- train_test(bin.x,bin.y,p=0.8)
nrow(traintest$train_X)
nrow(traintest$test_X)
```

# prescreeing(X,y,K)
This function performs pre-screening on predictor variable, evaluating which predictor variable is most informative based on absolute value of correlation to response variable. In addition to matrix X and vector y, users are required to determine K, the number of informative predictors. It returns the names of K most informative predictors. 
```{r}
prescreening(bin.x,bin.y,K=5)
```

#1 Fitting model
Fitting different types of models is a fundamental task in data analysis and machine learning. This package provides a rich ecosystem of packages for fitting various types of modes. This tutorial covers how to fit the following models using built-in datasets in the package. 
1. Linear model
2. Logistic model
3. Ridge model
4. LASSO model
5. Elastic net model
6. Random forest model

#1.Linear model
fitLinearModel() function allows users to fit linear model. It only accepts continuous y vector.
```{r}
linear_model <- fitLinearModel(cont.x,cont.y)
```
#2. Logistic model
fitLogisticModel() function allows users to fit logistic model. It only accepts binary y vector.
```{r}
logistic_model <- fitLogisticModel(bin.x,bin.y)
```
#3. Ridge model
fitRidgeModel() function allows users to fit ridge regularization model. It accepts both binary and continuous y vector. 
```{r}
ridge_model <- fitRidgeModel(bin.x,bin.y)
```
#4. LASSO model
fitLassoModel() function allows users to fit LASSO regularization model. It accepts both binary and continuous y vector.
```{r}
lasso_model <- fitLassoModel(cont.x,cont.y)
```
#5. Elastic net model
fitElasticNetmodel() function allows users to fit elastic net regularization model. It accepts both binary and continuous y vector.
```{r}
elasticnet_model <- fitElasticNetModel(bin.x,bin.y)
```
#6. Random forest model
fitRandomForestModel() function allows users to fit random forest model. It accepts both binary and continuous y vector. ntree, refers to the number of tree in random forest model, is set 500 as default. Users can alter the number of tree by specifying a parameter 'ntree'.
```{r}
randomforest_model <- fitRandomForestModel(cont.x,cont.y,ntree=500)
```

# Bagging
Bootstrap bagging is a technique used to imporve the stability and accuracy of machine learning algorithms, especially those prone to high variance. It involves training multiple models on different subsets of the training data and then combining their predictions to make more robust predictions. 
#1. Fit bagging model
First, fitting bootstrap bagging model is required. Users must specify R, the number of bootstrap replicates to perform.
This function generates logistic model regarding selected samples, and collect coefficients of each models. Final model is generated by computing means of coefficients. 
```{r}
baggingLogistic(bin.x,bin.y,50)
```
#2. Make prediction
Users can make predictions based on the bootstrap bagging model by using baggingPrediction() function. This function first divide train and test data. The proportion of train and test data is set 0.8 as default. Then users are given selections for which model to perform bagging process. The number of replicates for bootstrap process is set 50 as default. If the given response data is binary, it returns accuracy and the confusion matrix of prediction and test data. If continuous, it returns RMSE(Root Mean Square Error) between prediction and test data. 

```{r}
baggingPrediction(bin.x,bin.y)
```

```{r}
baggingPrediction(cont.x,cont.y)
```